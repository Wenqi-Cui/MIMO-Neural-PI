{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD52deps8Lra"
      },
      "source": [
        "# Install package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqD27N96mzOA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08dad285-a19a-4b8d-b942-c1d16fa53cae"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPpSGDcHm5T3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11801455-bf0f-4b6c-fdb7-b8db00916fb1"
      },
      "source": [
        "!pip install mat4py\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mat4py\n",
            "  Downloading mat4py-0.5.0-py2.py3-none-any.whl (13 kB)\n",
            "Installing collected packages: mat4py\n",
            "Successfully installed mat4py-0.5.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPdvp47f8Lrb",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81edc1ff-a213-4b2e-c5d9-0784eb80abc7"
      },
      "source": [
        "# A RNN-based Reinforcement Learning Framework for Frequency Control Problem with Stability Guarantee\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "import gym\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "import os\n",
        "import random\n",
        "from tensorflow.keras import models, layers, optimizers\n",
        "from tensorflow.keras.layers import RNN\n",
        "import tensorflow.keras.backend as K\n",
        "import sys\n",
        "from gym import spaces\n",
        "from gym.utils import seeding\n",
        "import copy\n",
        "from mat4py import loadmat\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import networkx as nx\n",
        "import scipy\n",
        "import pickle\n",
        "import time\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if (distutils.version.LooseVersion(tf.__version__) <\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from datetime import datetime\n",
        "random.seed(datetime.now())"
      ],
      "metadata": {
        "id": "Ja-GgbMSxr4S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9abd9c48-0a2d-419d-8963-0f05b2aa0139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "<ipython-input-4-ffa94a10b395>:3: DeprecationWarning: Seeding based on hashing is deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version. The only \n",
            "supported seed types are: None, int, float, str, bytes, and bytearray.\n",
            "  random.seed(datetime.now())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGE94Q4GABya"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEdncMMcmduT",
        "scrolled": true
      },
      "source": [
        "# Frequency Control Porblem Environment\n",
        "class Frequency(gym.Env):\n",
        "    def  __init__(self, Pm,M,D,F,delta_t,max_action,dim_action,Penalty_action, coef_cost):\n",
        "        self.param_gamma = 1\n",
        "        self.sigma_e=0.05\n",
        "        self.M = M\n",
        "        self.D = D\n",
        "        self.Pm = Pm\n",
        "        self.max_action = max_action\n",
        "        self.dim_action = dim_action\n",
        "        self.omega_scale = 2*np.pi# this change the unit of omega to Hz\n",
        "        self.viewer  =  None\n",
        "        self.state_x = []\n",
        "        self.delta_t = delta_t\n",
        "        self.Penalty_action = Penalty_action\n",
        "        self.state_x_transfer1 = np.vstack((np.hstack((np.identity(dim_action,dtype = np.float32),np.zeros((dim_action,dim_action),dtype = np.float32))),\\\n",
        "                                np.hstack((delta_t*self.omega_scale*np.identity(dim_action,dtype = np.float32),\\\n",
        "                                           np.identity(dim_action,dtype = np.float32)-delta_t*np.diag(D/M)))))\n",
        "\n",
        "        self.state_x_transferF = -delta_t*(((M**(-1)).reshape(dim_action,1))@np.ones((1,dim_action),dtype = np.float32))*F\n",
        "        self.state_x_transfer2 = np.hstack((np.zeros((dim_action,dim_action),dtype = np.float32),\\\n",
        "                                        np.identity(dim_action,dtype = np.float32)))\n",
        "\n",
        "        self.state_x_transfer3 = np.hstack((np.zeros((1,dim_action),dtype = np.float32),\\\n",
        "                                        delta_t*Pm*(M**(-1))))\n",
        "        self.state_x_transfer3_Pm = np.hstack((np.zeros((dim_action,dim_action),dtype = np.float32),\\\n",
        "                                        delta_t*np.diag((M**(-1)))))\n",
        "        self.state_x_transfer4 = np.hstack((np.zeros((dim_action,dim_action),dtype = np.float32),\\\n",
        "                                        -delta_t*np.diag((M**(-1)))))\n",
        "\n",
        "        self.select_add_w = np.vstack((np.zeros((dim_action,1),dtype = np.float32),\\\n",
        "                                        np.ones((dim_action,1),dtype = np.float32)))\n",
        "        self.select_w = np.vstack((np.zeros((dim_action,dim_action),dtype = np.float32),\\\n",
        "                                        np.identity(dim_action,dtype = np.float32)))\n",
        "        self.select_delta = np.vstack((np.identity(dim_action,dtype = np.float32),\\\n",
        "                                        np.zeros((dim_action,dim_action),dtype = np.float32)))\n",
        "        self.diag_c  =  np.diag(coef_cost)\n",
        "\n",
        "        # np.identity(dim_action,dtype = np.float32)\n",
        "\n",
        "\n",
        "    def step(self, action,Pm):\n",
        "\n",
        "        cost_action, grad_action  =  self.calc_grad_action(action)\n",
        "        dot_s_new  =  self.state_x@self.select_w-\\\n",
        "                np.sum(np.transpose(grad_action)@np.ones((1,dim_action),dtype = np.float32)\\\n",
        "                - np.ones((dim_action,1),dtype = np.float32)@grad_action,axis = 1)@self.diag_c*0.05\n",
        "        self.state_x  =  copy.deepcopy(self.state_x@self.state_x_transfer1\\\n",
        "              + np.sum(np.sin( np.transpose(self.state_x@self.select_delta)@np.ones((1,dim_action),dtype = np.float32)-\\\n",
        "                np.ones((dim_action,1),dtype = np.float32)@(self.state_x@self.select_delta))*self.state_x_transferF,axis = 1 )\\\n",
        "                      @self.state_x_transfer2\\\n",
        "              + Pm@self.state_x_transfer3_Pm\\\n",
        "                          +action@self.state_x_transfer4)\n",
        "        self.state_s  =  self.state_s+self.delta_t*dot_s_new/1\n",
        "        loss  =  self.param_gamma*pow(self.state_x,2)@self.select_add_w\n",
        "        return self.state_s, self.state_x, loss\n",
        "\n",
        "\n",
        "\n",
        "    def step_PI_CommEdge_WoCost(self, actionP, actionI,Pm):\n",
        "\n",
        "        action  =  actionP + actionI\n",
        "        dot_s_new  =  self.state_x@self.select_w\n",
        "        self.state_x  =  copy.deepcopy(self.state_x@self.state_x_transfer1\\\n",
        "              + np.sum(np.sin( np.transpose(self.state_x@self.select_delta)@np.ones((1,dim_action),dtype = np.float32)-\\\n",
        "                np.ones((dim_action,1),dtype = np.float32)@(self.state_x@self.select_delta))*self.state_x_transferF,axis = 1 )\\\n",
        "                      @self.state_x_transfer2\\\n",
        "              + Pm@self.state_x_transfer3_Pm\\\n",
        "                          +action@self.state_x_transfer4)\n",
        "        self.state_s  =  self.state_s+self.delta_t*dot_s_new/1\n",
        "        loss  =  self.param_gamma*pow(self.state_x,2)@self.select_add_w\n",
        "        return self.state_s, self.state_x, loss\n",
        "\n",
        "\n",
        "    def set_state(self, state_input):\n",
        "        self.state_x = state_input\n",
        "        self.state_s  =  np.zeros((1,dim_action),dtype = np.float32)\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        initial_state1 = np.random.uniform(0.0,0.3,(1,self.dim_action))\n",
        "        initial_state2 = np.random.uniform(-0.03,0.03,(1,self.dim_action))\n",
        "        s_concate = np.hstack((initial_state1,initial_state2)).astype(np.float32)\n",
        "        self.state_x  =  s_concate\n",
        "        self.state_s  =  np.zeros((1,dim_action),dtype = np.float32)\n",
        "\n",
        "        return self.state_x\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulation data load from IEEE 39-bus system\n",
        "data = loadmat('IEEE_39bus_Kron_new.mat')\n",
        "\n",
        "K_EN=data['Kron_39bus']['K']\n",
        "K_EN=np.asarray(K_EN, dtype=np.float32)\n",
        "\n",
        "H=data['Kron_39bus']['H']\n",
        "H=np.asarray(H, dtype=np.float32)\n",
        "\n",
        "Damp=data['Kron_39bus']['D']\n",
        "Damp=np.asarray(Damp, dtype=np.float32)\n",
        "\n",
        "omega_R=data['Kron_39bus']['omega_R']\n",
        "\n",
        "A_EN=data['Kron_39bus']['A']\n",
        "A_EN=np.asarray(A_EN, dtype=np.float32)\n",
        "\n",
        "gamma=data['Kron_39bus']['gamma']\n",
        "gamma=np.asarray(gamma, dtype=np.float32)"
      ],
      "metadata": {
        "id": "WM-_-95KQDb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim_action = 10 #dimension of action space\n",
        "dim_state = 2*dim_action #dimension of state space\n",
        "action_units=dim_action\n",
        "delta_t=0.01\n",
        "M=H.reshape(dim_action)*2/omega_R*2*np.pi\n",
        "# D=Damp.reshape(dim_action)/omega_R*2*np.pi\n",
        "D=np.zeros(dim_action,dtype=np.float32)\n",
        "D[0]=2*590/100\n",
        "D[1:8]=2*865/100\n",
        "D[8:10]=2*911/100;\n",
        "D=D/omega_R*2*np.pi\n",
        "F=K_EN\n",
        "Penalty_action=0.01*0.2\n",
        "Pm=np.array([[-0.19983394, -0.25653884, -0.25191885, -0.10242008, -0.34510365,\n",
        "         0.23206371,  0.4404325 ,  0.5896664 ,  0.26257738, -0.36892462]],dtype=np.float32)\n",
        "\n",
        "max_action=np.array([[0.19606592, 0.2190382 , 0.22375287, 0.0975513 , 0.29071101,\n",
        "        0.22091283, 0.38759459, 0.56512538, 0.24151538, 0.29821917]],dtype=np.float32)*5\n",
        "equilibrium_init=np.array([[ -0.05420687, -0.07780334, -0.07351729, -0.05827823, -0.09359571,\n",
        "        -0.02447385, -0.00783582,  0.00259523, -0.0162409 , -0.06477749,\n",
        "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
        "         0.        ,  0.        ,  0.        ,  0.        ,  0.       ]],dtype=np.float32)\n",
        "coef_cost = np.array([0.94162537, 1.15464676, 0.55487802, 0.71176656, 1.27476119,\n",
        "       1.02529959, 1.2946042 , 1.01800112, 0.99465694, 0.73467357], dtype=np.float32)\n",
        "# np.random.uniform(0.5,1.5,(dim_action))\n",
        "env = Frequency(Pm,M,D,F,delta_t,max_action,dim_action,Penalty_action, coef_cost)\n"
      ],
      "metadata": {
        "id": "XTGiBCYuVdH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJNB8I_o0AN0"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural-PI"
      ],
      "metadata": {
        "id": "Y3tffH3F0AN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN Cell to integrate state transition dynamics\n",
        "class MinimalRNNCell_WoCost_SCNN(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units, action_units_node_p, action_units_node_i, internal_units,internal_units_SCNN, env,batchsize,**kwargs):\n",
        "        self.units = units\n",
        "        self.state_size = units\n",
        "        self.action_units_node_p = action_units\n",
        "        self.action_units_node_i = action_units\n",
        "        self.internal_units = internal_units\n",
        "        self.internal_units_SCNN = internal_units_SCNN\n",
        "        self.batchsize = batchsize\n",
        "        self.delta_t = tf.constant(env.delta_t,dtype = tf.float32)\n",
        "\n",
        "        self.state_x_transfer1 = tf.constant(env.state_x_transfer1,dtype = tf.float32)\n",
        "        self.state_x_transferF = tf.constant(env.state_x_transferF,dtype = tf.float32)\n",
        "        self.state_x_transfer2 = tf.constant(env.state_x_transfer2,dtype = tf.float32)\n",
        "        self.state_x_transfer3 = tf.constant(env.state_x_transfer3,dtype = tf.float32)\n",
        "        self.state_x_transfer4 = tf.constant(env.state_x_transfer4,dtype = tf.float32)\n",
        "        self.state_x_transfer3_Pm = tf.constant(env.state_x_transfer3_Pm,dtype = tf.float32)\n",
        "        self.select_add_w = tf.constant(env.select_add_w,dtype = tf.float32)\n",
        "        self.select_w = tf.constant(env.select_w,dtype = tf.float32)\n",
        "        self.select_delta = tf.constant(env.select_delta,dtype = tf.float32)\n",
        "        self.max_action = tf.constant(env.max_action,dtype = tf.float32)\n",
        "        self.w_recover = tf.constant(tf.linalg.band_part(-tf.ones((internal_units,internal_units)),0,1)\\\n",
        "                                        +2*tf.eye(internal_units),dtype = tf.float32)\n",
        "        self.b_recover = tf.constant(tf.linalg.band_part(tf.ones((internal_units,internal_units)),0,-1)\\\n",
        "                                        -tf.eye(internal_units),dtype = tf.float32)\n",
        "        self.diag_c = tf.constant(env.diag_c, dtype = tf.float32)\n",
        "############ PI controller :P\n",
        "\n",
        "        self.Multiply_ones_node_p = tf.tile(tf.ones((action_units_node_p,action_units_node_p),dtype=np.float32)[None], [batchsize, 1, 1])\n",
        "        self.ones_node_p = tf.ones((action_units_node_p,internal_units),dtype=tf.float32)\n",
        "\n",
        "############ PI controller :I\n",
        "        self.Multiply_ones_node_i = tf.tile(tf.ones((action_units_node_i,action_units_node_i),dtype=np.float32)[None], [batchsize, 1, 1])\n",
        "        self.ones_node_i = tf.ones((action_units_node_i,internal_units),dtype=tf.float32)\n",
        "        self.obs_zeros = tf.zeros((1, action_units_node_p))\n",
        "\n",
        "\n",
        "        super(MinimalRNNCell_WoCost_SCNN, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "############# PI controller  : P\n",
        "        self.W_p1 =  self.add_weight(\n",
        "            shape=(self.action_units_node_p,self.internal_units_SCNN),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='W_p1')\n",
        "        self.b_p1 =  self.add_weight(\n",
        "            shape=(self.internal_units_SCNN,),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='b_p1')\n",
        "        self.W_p2 =  self.add_weight(\n",
        "            shape=(self.action_units_node_p,self.internal_units_SCNN),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='W_p2')\n",
        "        self.W_pz1 =  self.add_weight(\n",
        "            shape=(self.internal_units_SCNN,self.internal_units_SCNN),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            constraint = tf.keras.constraints.non_neg(),\n",
        "            name='W_pz1')\n",
        "        self.b_p2 =  self.add_weight(\n",
        "            shape=(self.internal_units_SCNN,),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='b_p2')\n",
        "\n",
        "        self.W_p3 =  self.add_weight(\n",
        "            shape=(self.action_units_node_p,1),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='W_p3')\n",
        "        self.W_pz2 =  self.add_weight(\n",
        "            shape=(self.internal_units_SCNN,1),\n",
        "            initializer='uniform',\n",
        "            trainable=True,\n",
        "            constraint = tf.keras.constraints.non_neg(),\n",
        "            name='W_pz2')\n",
        "        self.b_p3 =  self.add_weight(\n",
        "            shape=(1,),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='b_p3')\n",
        "\n",
        "        ######################### integral\n",
        "        self.W_i1 =  self.add_weight(\n",
        "            shape=(self.action_units_node_p,self.internal_units_SCNN),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='W_i1')\n",
        "        self.b_i1 =  self.add_weight(\n",
        "            shape=(self.internal_units_SCNN,),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='b_i1')\n",
        "        self.W_i2 =  self.add_weight(\n",
        "            shape=(self.action_units_node_p,self.internal_units_SCNN),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='W_i2')\n",
        "        self.W_iz1 =  self.add_weight(\n",
        "            shape=(self.internal_units_SCNN,self.internal_units_SCNN),\n",
        "            initializer='uniform',\n",
        "            trainable=True,\n",
        "            constraint = tf.keras.constraints.non_neg(),\n",
        "            name='W_iz1')\n",
        "        self.b_i2 =  self.add_weight(\n",
        "            shape=(self.internal_units_SCNN,),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='b_i2')\n",
        "\n",
        "        self.W_i3 =  self.add_weight(\n",
        "            shape=(self.action_units_node_p,1),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='W_i3')\n",
        "        self.W_iz2 =  self.add_weight(\n",
        "            shape=(self.internal_units_SCNN,1),\n",
        "            initializer='uniform',\n",
        "            trainable=True,\n",
        "            constraint = tf.keras.constraints.non_neg(),\n",
        "            name='W_iz2')\n",
        "        self.b_i3 =  self.add_weight(\n",
        "            shape=(1,),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='b_i3')\n",
        "\n",
        "\n",
        "        self.w_beta =  self.add_weight(\n",
        "            # shape=(1),\n",
        "            initializer=tf.constant_initializer(1),\n",
        "            trainable=True,\n",
        "            name='beta')\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    @tf.function\n",
        "    def SCNN_action(self, obs):\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(obs)\n",
        "            z1 = self.softplus_beta(K.dot(obs, self.W_p1)+ self.b_p1)\n",
        "            z2 = self.softplus_beta(K.dot(obs, self.W_p2)+K.dot(z1, self.W_pz1)+ self.b_p2)\n",
        "            z3 = self.softplus_beta(K.dot(obs, self.W_p3)+K.dot(z2, self.W_pz2)+ self.b_p3)\n",
        "        action_node_p = tf.squeeze(tape.batch_jacobian(z3, obs))\n",
        "        return action_node_p\n",
        "\n",
        "    @tf.function\n",
        "    def SCNN_actionI(self, obs):\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(obs)\n",
        "            z1 = self.softplus_beta(K.dot(obs, self.W_i1)+ self.b_i1)\n",
        "            z2 = self.softplus_beta(K.dot(obs, self.W_i2)+K.dot(z1, self.W_iz1)+ self.b_i2)\n",
        "            z3 = self.softplus_beta(K.dot(obs, self.W_i3)+K.dot(z2, self.W_iz2)+ self.b_i3)\n",
        "        action_node_i = 1*tf.squeeze(tape.batch_jacobian(z3, obs))\n",
        "\n",
        "        return action_node_i\n",
        "\n",
        "    @tf.function\n",
        "    def softplus_beta(self, x):\n",
        "\n",
        "        return K.softplus(self.w_beta*x)/(self.w_beta)\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs, states):\n",
        "        # stacked ReLU structure to represent control network\n",
        "        prev_state = states[0]\n",
        "        prev_state_x = prev_state[:,0:self.action_units_node_p*2]\n",
        "        prev_state_s =  prev_state[:,self.action_units_node_p*2:self.action_units_node_p*3]\n",
        "##################### PI: P\n",
        "\n",
        "        obs_y = K.dot(prev_state_x,self.select_w)\n",
        "        action_node_p = self.SCNN_action(obs_y)-self.SCNN_action(self.obs_zeros)\n",
        "\n",
        "\n",
        "##################### PI: I\n",
        "\n",
        "        action_node_i = self.SCNN_actionI(prev_state_s)-self.SCNN_actionI(self.obs_zeros)\n",
        "\n",
        "\n",
        "###########################\n",
        "        action_nonconstrain = action_node_p + action_node_i\n",
        "        action =  self.max_action-K.relu(self.max_action-action_nonconstrain)+K.relu(-self.max_action-action_nonconstrain)\n",
        "        #\n",
        "#########################\n",
        "        # calculate state on s\n",
        "        dot_s = K.dot(prev_state_x,self.select_w)\n",
        "\n",
        "#######################\n",
        "        # integrate the state transition dynamics\n",
        "        new_state_x = K.dot(prev_state_x, self.state_x_transfer1)+\\\n",
        "            K.dot(K.sum(K.sin( K.dot(tf.linalg.diag(K.dot(prev_state_x, self.select_delta)),tf.ones((dim_action,dim_action),dtype = np.float32))-\\\n",
        "                                tf.matmul(self.Multiply_ones_node_p,tf.linalg.diag(K.dot(prev_state_x, self.select_delta))))\\\n",
        "                        *self.state_x_transferF,axis = 2 )\\\n",
        "                                      ,self.state_x_transfer2)\\\n",
        "                             + self.state_x_transfer3+K.dot(action,self.state_x_transfer4)\\\n",
        "                             + inputs@self.state_x_transfer3_Pm\n",
        "\n",
        "\n",
        "        loss0 = K.dot(K.pow(new_state_x,2),self.select_add_w)\n",
        "        frequency = K.dot(new_state_x,self.select_w)\n",
        "        new_state_s = prev_state_s + self.delta_t*dot_s\n",
        "        next_state = tf.concat([new_state_x,  new_state_s], axis = 1)\n",
        "        return [loss0,frequency,action_node_p,action_node_i, action], [next_state]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "E9k9PfnW0AN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loop_seed = 5\n",
        "model_list = []\n",
        "loss_list = []\n",
        "episodes  = 400 # total number of iterations to update weights\n",
        "units = dim_action*3 #dimension of each state\n",
        "internal_units = 20 # demension of the neural network for control policy\n",
        "internal_units_SCNN = 20\n",
        "T = 400  #Total period considered\n",
        "Batch_num = 300\n",
        "# Batch_num = 300 # number of batch in each episodes\n",
        "PrintUpdate = 50\n",
        "Comp_time_list = []\n",
        "\n",
        "for loop in range(3,loop_seed):\n",
        "    random.seed(datetime.now())\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    cell_WoCost_SCNN = MinimalRNNCell_WoCost_SCNN(units,dim_action, dim_action, internal_units, internal_units_SCNN, env,Batch_num)\n",
        "    layer_WoCost_SCNN = RNN(cell_WoCost_SCNN,return_sequences = True,stateful = True)\n",
        "    input_1 = tf.keras.Input(batch_shape = (Batch_num,T,dim_action))\n",
        "    outputs = layer_WoCost_SCNN((input_1))\n",
        "    model_WoCost_SCNN = tf.keras.models.Model([input_1], outputs)\n",
        "    model_WoCost_SCNN.compile(optimizer = 'adam', loss = 'mse', metrics = ['accuracy'])\n",
        "\n",
        "    x0 = np.ones((Batch_num,T,dim_action))\n",
        "    y0 = model_WoCost_SCNN(x0)\n",
        "    Loss_record = []\n",
        "    Pe_rnn_record = []\n",
        "    global_step = tf.Variable(0, trainable = False)\n",
        "    learning_rate_initial = 0.05\n",
        "\n",
        "    decayed_lr  = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        learning_rate_initial, 50, 0.7, staircase = True)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = decayed_lr)\n",
        "\n",
        "    delta_rnn_init_bound = 0.05*0\n",
        "    omega_rnn_init_bound = 0.1*0 #in Hz\n",
        "    num_gen_step = 3\n",
        "    Percent_step_change = 1\n",
        "    range_step_change = 1\n",
        "    for i in range(0,episodes):\n",
        "        start_in = time.time()\n",
        "        initial_state = np.zeros((Batch_num,action_units*2))+equilibrium_init\n",
        "        Pm_change = np.zeros((Batch_num,T,dim_action))\n",
        "        for gen_interupt in range(0, num_gen_step):\n",
        "            idx_gen_deviation = np.random.randint(0, action_units, Batch_num*Percent_step_change)\n",
        "            idx_batch_deviation = np.random.randint(0, Batch_num, Batch_num*Percent_step_change)\n",
        "            slot_start_deviation = np.random.randint(0, T/20, Batch_num*Percent_step_change)\n",
        "            step_change = np.random.uniform(-1,1,(Batch_num*Percent_step_change))*range_step_change\n",
        "            for t_interupt in range(0,T):\n",
        "                Pm_change[idx_batch_deviation,t_interupt, idx_gen_deviation]\\\n",
        "                                = (slot_start_deviation<= t_interupt)*step_change\n",
        "        layer_WoCost_SCNN.reset_states( np.hstack((initial_state, np.zeros((Batch_num,action_units)))))\n",
        "        with tf.GradientTape(persistent = True) as tape:\n",
        "            [loss0,frequency,action0,actions, action] = model_WoCost_SCNN(Pm_change)\n",
        "            loss_action =0.005*K.sum(K.pow(action,2))/Batch_num\n",
        "            loss_freq = K.sum(K.max(K.abs(frequency),axis = 1))/Batch_num + 0.05*K.sum(K.abs(frequency))/Batch_num\n",
        "            loss = loss_action + loss_freq\n",
        "\n",
        "        grads = tape.gradient(loss, model_WoCost_SCNN.variables)\n",
        "        optimizer.apply_gradients(zip(grads, model_WoCost_SCNN.variables))\n",
        "        Loss_record.append(loss)\n",
        "\n",
        "        if i % (PrintUpdate) ==  0:\n",
        "            print('episode',i, 'Loss',loss)\n",
        "            print('episode',i, 'Loss_frequency',loss_freq)\n",
        "            print('            time,',  time.time()- start_in  )\n",
        "\n",
        "    end = time.time()\n",
        "    print(end - start)\n",
        "    Comp_time_list.append(end - start)\n",
        "\n",
        "    model_list.append(model_WoCost_SCNN)\n",
        "    loss_list.append(np.array(Loss_record))\n",
        "\n",
        "print('computation time ', np.array(Comp_time_list))\n",
        "print('computation time mean', np.mean(np.array(Comp_time_list)))"
      ],
      "metadata": {
        "id": "PWsFZaQEW0rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(Loss_record)\n",
        "plt.xlabel('episoid')\n",
        "plt.ylabel('Loss')\n"
      ],
      "metadata": {
        "id": "pk7-ZeUf0AN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear-PI"
      ],
      "metadata": {
        "id": "hoi8Mg8Ff6tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN Cell to integrate state transition dynamics\n",
        "class MinimalRNNCell_WoCost_Linear(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units, action_units_node_p, action_units_node_i, internal_units,internal_units_ICNN, env,batchsize,**kwargs):\n",
        "        self.units = units\n",
        "        # self.action_units = action_units\n",
        "        self.state_size = units\n",
        "        self.action_units_node_p = action_units\n",
        "        self.action_units_node_i = action_units\n",
        "        self.internal_units = internal_units\n",
        "        self.internal_units_ICNN = internal_units_ICNN\n",
        "        self.batchsize = batchsize\n",
        "        self.delta_t = tf.constant(env.delta_t,dtype = tf.float32)\n",
        "\n",
        "        self.state_x_transfer1 = tf.constant(env.state_x_transfer1,dtype = tf.float32)\n",
        "        self.state_x_transferF = tf.constant(env.state_x_transferF,dtype = tf.float32)\n",
        "        self.state_x_transfer2 = tf.constant(env.state_x_transfer2,dtype = tf.float32)\n",
        "        self.state_x_transfer3 = tf.constant(env.state_x_transfer3,dtype = tf.float32)\n",
        "        self.state_x_transfer4 = tf.constant(env.state_x_transfer4,dtype = tf.float32)\n",
        "        self.state_x_transfer3_Pm = tf.constant(env.state_x_transfer3_Pm,dtype = tf.float32)\n",
        "        self.select_add_w = tf.constant(env.select_add_w,dtype = tf.float32)\n",
        "        self.select_w = tf.constant(env.select_w,dtype = tf.float32)\n",
        "        self.select_delta = tf.constant(env.select_delta,dtype = tf.float32)\n",
        "        self.max_action = tf.constant(env.max_action,dtype = tf.float32)\n",
        "        # self.Multiply_ones = tf.tile(tf.ones((action_units,action_units),dtype = np.float32)[None], [batchsize, 1, 1])\n",
        "        self.w_recover = tf.constant(tf.linalg.band_part(-tf.ones((internal_units,internal_units)),0,1)\\\n",
        "                                        +2*tf.eye(internal_units),dtype = tf.float32)\n",
        "        self.b_recover = tf.constant(tf.linalg.band_part(tf.ones((internal_units,internal_units)),0,-1)\\\n",
        "                                        -tf.eye(internal_units),dtype = tf.float32)\n",
        "        # self.ones_frequency = tf.ones((action_units,internal_units),dtype = tf.float32)\n",
        "        self.diag_c = tf.constant(env.diag_c, dtype = tf.float32)\n",
        "        self.incidence_communication = tf.constant(env.incidence_communication,dtype = tf.float32)\n",
        "   ############ PI controller :P\n",
        "\n",
        "        # self.max_action_node_p = tf.constant(env.max_action_node_p,dtype=tf.float32)\n",
        "        self.Multiply_ones_node_p = tf.tile(tf.ones((action_units_node_p,action_units_node_p),dtype=np.float32)[None], [batchsize, 1, 1])\n",
        "        self.ones_node_p = tf.ones((action_units_node_p,internal_units),dtype=tf.float32)\n",
        "\n",
        "        self.collect_W_p = []\n",
        "        self.collect_W_i = []\n",
        "\n",
        "        super(MinimalRNNCell_WoCost_Linear, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "############# PI controller  : P\n",
        "        for comm_subset in Comm_set:\n",
        "            subset_dim = np.shape(comm_subset)[0]\n",
        "            self.W_p =  self.add_weight(\n",
        "                shape=(self.subset_dim,self.subset_dim),\n",
        "                initializer='random_normal',\n",
        "                trainable=True,\n",
        "                name='W_p')\n",
        "            self.collect_W_p.append(self.W_p)\n",
        "\n",
        "\n",
        "            ######################### integral\n",
        "            self.W_i =  self.add_weight(\n",
        "                shape=(self.subset_dim,self.subset_dim),\n",
        "                initializer='random_normal',\n",
        "                trainable=True,\n",
        "                name='W_i')\n",
        "            self.collect_W_i.append(self.W_i)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    @tf.function\n",
        "    def action_linear_p_subset(self, obs):\n",
        "        action =\n",
        "        for comm_subset in Comm_set:\n",
        "            subset_idx = comm_subset\n",
        "            action += K.dot(obs_y[:,subset_idx], self.W_p)\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs, states):\n",
        "        # stacked ReLU structure to represent control network\n",
        "        prev_state = states[0]\n",
        "        prev_state_x = prev_state[:,0:self.action_units_node_p*2]\n",
        "        prev_state_s =  prev_state[:,self.action_units_node_p*2:self.action_units_node_p*3]\n",
        "\n",
        "\n",
        "##################### PI: P\n",
        "\n",
        "        obs_y = K.dot(prev_state_x,self.select_w)\n",
        "\n",
        "        action_node_p = K.dot(obs_y, self.W_p)\n",
        "\n",
        "\n",
        "##################### PI: I\n",
        "\n",
        "        action_node_i = K.dot(prev_state_s,  self.W_i)\n",
        "\n",
        "\n",
        "###########################\n",
        "        action_nonconstrain = action_node_p + action_node_i\n",
        "        action =  self.max_action-K.relu(self.max_action-action_nonconstrain)+K.relu(-self.max_action-action_nonconstrain)\n",
        "        #\n",
        "#########################\n",
        "        # calculate state on s\n",
        "        dot_s = K.dot(prev_state_x,self.select_w)\n",
        "\n",
        "#######################\n",
        "        # integrate the state transition dynamics\n",
        "        new_state_x = K.dot(prev_state_x, self.state_x_transfer1)+\\\n",
        "            K.dot(K.sum(K.sin( K.dot(tf.linalg.diag(K.dot(prev_state_x, self.select_delta)),tf.ones((dim_action,dim_action),dtype = np.float32))-\\\n",
        "                                tf.matmul(self.Multiply_ones_node_p,tf.linalg.diag(K.dot(prev_state_x, self.select_delta))))\\\n",
        "                        *self.state_x_transferF,axis = 2 )\\\n",
        "                                      ,self.state_x_transfer2)\\\n",
        "                             + self.state_x_transfer3+K.dot(action,self.state_x_transfer4)\\\n",
        "                             + inputs@self.state_x_transfer3_Pm\n",
        "\n",
        "\n",
        "        loss0 = K.dot(K.pow(new_state_x,2),self.select_add_w)\n",
        "        frequency = K.dot(new_state_x,self.select_w)\n",
        "        new_state_s = prev_state_s + self.delta_t*dot_s\n",
        "        next_state = tf.concat([new_state_x,  new_state_s], axis = 1)\n",
        "        return [loss0,frequency,action_node_p,action_node_i, action], [next_state]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fJKXzc84f6tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loop_seed = 5\n",
        "PI_Linear_list = []\n",
        "loss_list = []\n",
        "Comp_time_list = []\n",
        "\n",
        "\n",
        "PrintUpdate = 100\n",
        "episodes =400 # total number of iterations to update weights\n",
        "\n",
        "\n",
        "units = dim_action*2 + dim_edge #dimension of each state\n",
        "internal_units=20 # demension of the neural network for control policy\n",
        "internal_units_Linear = 20\n",
        "\n",
        "T = 300  #Total period considered\n",
        "Batch_num=300 # number of batch in each episodes\n",
        "PrintUpdate=1\n",
        "\n",
        "for loop in range(0,loop_seed):\n",
        "    random.seed(datetime.now())\n",
        "    start = time.time()\n",
        "\n",
        "\n",
        "    cell = MinimalRNNCell_Linear(units, dim_edge ,dim_action, dim_action, internal_units, internal_units_Linear,env,Batch_num)\n",
        "    layer = RNN(cell,return_sequences=True,stateful = True)\n",
        "    input_1 = tf.keras.Input(batch_shape=(Batch_num,T,units))\n",
        "    outputs = layer((input_1))\n",
        "    model_Linear = tf.keras.models.Model([input_1], outputs)\n",
        "    model_Linear.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "\n",
        "    x0=np.ones((Batch_num,T,units))\n",
        "    y0=model_Linear(x0)\n",
        "    Loss_record_Linear=[]\n",
        "    Pe_rnn_record=[]\n",
        "    global_step = tf.Variable(0, trainable=False)\n",
        "    learning_rate_initial=0.05\n",
        "    decayed_lr =tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        learning_rate_initial, 50, 0.7, staircase=True)\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=decayed_lr)\n",
        "\n",
        "\n",
        "    for i in range(0,episodes):\n",
        "        start_in = time.time()\n",
        "\n",
        "        initial_state1 = v0_nom*np.ones((Batch_num,dim_action)) + v0_random*np.random.uniform(0,1.,(Batch_num, dim_action))\n",
        "        initial_state2 = env.eta0*np.ones((Batch_num,dim_edge))\n",
        "        initial_state3 = np.zeros((Batch_num, dim_action))\n",
        "        initial_state = np.hstack((initial_state1, initial_state2, initial_state3))\n",
        "        layer.reset_states( initial_state)\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            [new_state_v, new_state_eta, action_edge, action_P, action_I]=model_Linear(x0)\n",
        "\n",
        "\n",
        "    ##################\n",
        "            loss_state1 =1* K.sum(K.relu(-new_state_eta+1))/Batch_num/units\n",
        "\n",
        "            state_v_minus_ref = new_state_v-env.state_v_ref\n",
        "            loss_state3 = K.sum(K.abs(state_v_minus_ref))/Batch_num/units\n",
        "            loss_action_edge = 0.01*K.sum(K.pow(action_edge, 2))/Batch_num/units\n",
        "            loss_action_w = 0.05*K.sum(K.pow(action_P+action_I,2)@env.diag_c)/Batch_num/units\n",
        "            loss = (loss_state3 + loss_action_edge + loss_action_w)\n",
        "\n",
        "\n",
        "        grads = tape.gradient(loss, model_Linear.variables)\n",
        "        optimizer.apply_gradients(zip(grads, model_Linear.variables))\n",
        "        Loss_record_Linear.append(loss)\n",
        "        if i % (PrintUpdate) == 0:\n",
        "            print('episode',i, 'Loss',loss)\n",
        "            print('   Loss_v_minus_ref',loss_state3, 'Loss_eta',loss_state1  )\n",
        "            print('   Loss_u_edge', loss_action_edge, 'loss_action_w', loss_action_w )\n",
        "            print('   up/ui',K.sum(K.pow(action_P,2)@env.diag_c)/K.sum(K.pow(action_I,2)@env.diag_c))\n",
        "            print('            time,',  time.time()- start_in  )\n",
        "\n",
        "\n",
        "\n",
        "    end = time.time()\n",
        "    print(end - start)\n",
        "    Comp_time_list.append(end - start)\n",
        "    PI_Linear_list.append(model_Linear)\n",
        "    loss_list.append(np.array(Loss_record_Linear))\n",
        "\n",
        "\n",
        "\n",
        "print('computation time ', np.array(Comp_time_list))\n",
        "print('computation time mean', np.mean(np.array(Comp_time_list)))"
      ],
      "metadata": {
        "id": "VR0LKz85f6tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(Loss_record_Linear)\n",
        "plt.xlabel('episoid')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Non-Discounted Loss without penalty')"
      ],
      "metadata": {
        "id": "ithDjXjYf6td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DenseNN-PI"
      ],
      "metadata": {
        "id": "yUMYv92c78Mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### edge and P control\n",
        "# RNN Cell to integrate state transition dynamics\n",
        "class MinimalRNNCell_NNMatrix(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units, action_units_edge, action_units_node_p, action_units_node_i, internal_units,internal_units_ICNN,env,batchsize,**kwargs):\n",
        "        self.units = units\n",
        "        self.action_units_edge = action_units_edge\n",
        "        self.action_units_node_p = action_units_node_p\n",
        "        self.action_units_node_i = action_units_node_i\n",
        "        self.state_size = units\n",
        "        self.internal_units = internal_units\n",
        "        self.internal_units_ICNN = internal_units_ICNN\n",
        "\n",
        "        self.batchsize=batchsize\n",
        "        self.delta_t = tf.constant(env.delta_t,dtype=tf.float32)\n",
        "\n",
        "        self.v0 = tf.constant(env.v0,dtype=tf.float32)\n",
        "        self.v1 = tf.constant(env.v1,dtype=tf.float32)\n",
        "        self.state_v_ref = tf.constant(env.state_v_ref*np.ones((batchsize, action_units_node_p)),dtype=tf.float32)\n",
        "        self.diag_v1 = tf.constant(env.diag_v1,dtype=tf.float32)\n",
        "        self.diag_K = tf.constant(env.diag_K ,dtype=tf.float32)\n",
        "        self.delta_t = tf.constant(env.delta_t ,dtype=tf.float32)\n",
        "        self.dim_action = env.dim_action\n",
        "        # tf.constant( ,dtype=tf.float32)\n",
        "        self.dim_edge = env.dim_edge\n",
        "        self.eta0 = tf.constant(env.eta0 ,dtype=tf.float32)\n",
        "        self. matrix_grad_action =  tf.constant(env.matrix_grad_action,dtype=tf.float32)\n",
        "\n",
        "\n",
        "        self.Penalty_action = tf.constant(env.Penalty_action ,dtype=tf.float32)\n",
        "        self.diag_c = tf.constant(env.diag_c ,dtype=tf.float32)\n",
        "        self.incidence = tf.constant(env.incidence ,dtype=tf.float32)\n",
        "        self.w_recover =tf.constant(tf.linalg.band_part(-tf.ones((internal_units,internal_units)),0,1)\\\n",
        "                                        +2*tf.eye(internal_units),dtype=tf.float32)\n",
        "        self.b_recover = tf.constant(tf.linalg.band_part(tf.ones((internal_units,internal_units)),0,-1)\\\n",
        "                                        -tf.eye(internal_units),dtype=tf.float32)\n",
        "\n",
        "########### edge\n",
        "\n",
        "        self.max_action_edge = tf.constant(env.max_action_edge,dtype=tf.float32)\n",
        "        self.Multiply_ones_edge = tf.tile(tf.ones((action_units_edge,action_units_edge),dtype=np.float32)[None], [batchsize, 1, 1])\n",
        "        self.ones_edge = tf.ones((action_units_edge,internal_units),dtype=tf.float32)\n",
        "\n",
        "############ PI controller :P\n",
        "\n",
        "        self.Multiply_ones_node_p = tf.tile(tf.ones((action_units_node_p,action_units_node_p),dtype=np.float32)[None], [batchsize, 1, 1])\n",
        "        self.ones_node_p = tf.ones((action_units_node_p,internal_units),dtype=tf.float32)\n",
        "\n",
        "############ PI controller :I\n",
        "        self.Multiply_ones_node_i = tf.tile(tf.ones((action_units_node_i,action_units_node_i),dtype=np.float32)[None], [batchsize, 1, 1])\n",
        "        self.ones_node_i = tf.ones((action_units_node_i,internal_units),dtype=tf.float32)\n",
        "        self.obs_zeros = tf.zeros((1, action_units_node_p))\n",
        "\n",
        "        self.linear_i = tf.zeros((action_units_node_i),dtype=np.float32)\n",
        "\n",
        "        super(MinimalRNNCell_NNMatrix, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "############## edge\n",
        "        self.w_plus_temp0_edge =  self.add_weight(\n",
        "            shape=(self.action_units_edge,self.internal_units),\n",
        "            # initializer=tf.constant_initializer(0.5),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='w_plus_temp')\n",
        "\n",
        "        self.b_plus_temp0_edge = self.add_weight(\n",
        "            shape=(self.action_units_edge,self.internal_units),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='b_plus_temp')\n",
        "        self.w_minus_temp0_edge =  self.add_weight(\n",
        "            shape=(self.action_units_edge,self.internal_units),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='w_minus_temp')\n",
        "\n",
        "        self.b_minus_temp0_edge = self.add_weight(\n",
        "            shape=(self.action_units_edge,self.internal_units),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='b_minus_temp')\n",
        "\n",
        "\n",
        "############# PI controller  : P\n",
        "        self.W_p1 =  self.add_weight(\n",
        "            shape=(self.action_units_node_p,self.internal_units_ICNN),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='W_p1')\n",
        "        self.b_p1 =  self.add_weight(\n",
        "            shape=(self.internal_units_ICNN,),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='b_p1')\n",
        "        self.W_p2 =  self.add_weight(\n",
        "            shape=(self.action_units_node_p,self.internal_units_ICNN),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='W_p2')\n",
        "        self.W_pz1 =  self.add_weight(\n",
        "            shape=(self.internal_units_ICNN,self.internal_units_ICNN),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='W_pz1')\n",
        "        self.b_p2 =  self.add_weight(\n",
        "            shape=(self.internal_units_ICNN,),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='b_p2')\n",
        "\n",
        "        self.W_p3 =  self.add_weight(\n",
        "            shape=(self.action_units_node_p,1),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='W_p3')\n",
        "        self.W_pz2 =  self.add_weight(\n",
        "            shape=(self.internal_units_ICNN,self.action_units_node_p),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='W_pz2')\n",
        "        self.b_p3 =  self.add_weight(\n",
        "            shape=(self.action_units_node_p,),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='b_p3')\n",
        "\n",
        "        ######################### integral\n",
        "        self.W_i1 =  self.add_weight(\n",
        "            shape=(self.action_units_node_p,self.internal_units_ICNN),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='W_i1')\n",
        "        self.b_i1 =  self.add_weight(\n",
        "            shape=(self.internal_units_ICNN,),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='b_i1')\n",
        "        self.W_i2 =  self.add_weight(\n",
        "            shape=(self.action_units_node_p,self.internal_units_ICNN),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='W_i2')\n",
        "        self.W_iz1 =  self.add_weight(\n",
        "            shape=(self.internal_units_ICNN,self.internal_units_ICNN),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='W_iz1')\n",
        "        self.b_i2 =  self.add_weight(\n",
        "            shape=(self.internal_units_ICNN,),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='b_i2')\n",
        "\n",
        "        self.W_i3 =  self.add_weight(\n",
        "            shape=(self.action_units_node_p,1),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='W_i3')\n",
        "        self.W_iz2 =  self.add_weight(\n",
        "            shape=(self.internal_units_ICNN,self.action_units_node_i),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='W_iz2')\n",
        "        self.b_i3 =  self.add_weight(\n",
        "            shape=(self.action_units_node_i,),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='b_i3')\n",
        "\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    @tf.function\n",
        "    def ICNN_action(self, obs):\n",
        "\n",
        "        z1 = K.softplus(K.dot(obs, self.W_p1)+ self.b_p1)\n",
        "        z2 = K.softplus(K.dot(obs, self.W_p2)+K.dot(z1, self.W_pz1)+ self.b_p2)\n",
        "        z3 = K.dot(obs, self.W_p3)+K.dot(z2, self.W_pz2)+ self.b_p3\n",
        "        return z3\n",
        "\n",
        "    @tf.function\n",
        "    def ICNN_actionI(self, obs):\n",
        "\n",
        "        z1 = K.softplus(K.dot(obs, self.W_i1)+ self.b_i1)\n",
        "        z2 = K.softplus(K.dot(obs, self.W_i2)+K.dot(z1, self.W_iz1)+ self.b_i2)\n",
        "        z3 = K.dot(obs, self.W_i3)+K.dot(z2, self.W_iz2)+ self.b_i3\n",
        "        return z3\n",
        "\n",
        "    @tf.function\n",
        "    def ICNN_edge(self, prev_state_eta):\n",
        "        action_nonconstrain0_edge = K.sum(K.relu(K.dot(tf.linalg.diag(prev_state_eta-self.eta0),self.w_plus_temp0_edge)\\\n",
        "                                         +self.b_plus_temp0_edge)*self.w_minus_temp0_edge+self.b_minus_temp0_edge,axis=2)\n",
        "        action_edge = self.max_action_edge - K.relu(self.max_action_edge-action_nonconstrain0_edge)\\\n",
        "                      +K.relu(-self.max_action_edge-action_nonconstrain0_edge)\n",
        "        return action_edge\n",
        "\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        # stacked ReLU structure to represent control network\n",
        "        prev_state = states[0]\n",
        "        prev_state_v = prev_state[:,0:self.dim_action]\n",
        "        prev_state_eta = prev_state[:, self.dim_action:self.dim_action+self.dim_edge]\n",
        "        prev_state_s =  prev_state[:,self.dim_action+self.dim_edge:self.dim_action*2+self.dim_edge]\n",
        "\n",
        "################ edge\n",
        "        action_edge = self.ICNN_edge(prev_state_eta)\n",
        "\n",
        "##################### PI: P\n",
        "        obs_y = -prev_state_v+self.state_v_ref\n",
        "        action_node_p = self.ICNN_action(obs_y)\n",
        "\n",
        "\n",
        "\n",
        "##################### PI: I\n",
        "\n",
        "\n",
        "        action_node_i = self.ICNN_actionI(prev_state_s)\n",
        "\n",
        "#########################\n",
        "        # calculate state on s\n",
        "        dot_s = -prev_state_v + self.state_v_ref\n",
        "\n",
        "\n",
        "#######################\n",
        "        # integrate the state transition dynamics\n",
        "\n",
        "\n",
        "        action_network = -K.dot(action_edge,tf.transpose(self.incidence))\n",
        "        dot_v = K.dot((-prev_state_v+self.v0) + K.dot(action_network+action_node_p+action_node_i,self.diag_v1), self.diag_K)\n",
        "        dot_eta = K.dot(prev_state_v, self.incidence)\n",
        "\n",
        "\n",
        "        new_state_v = prev_state_v + self.delta_t*dot_v\n",
        "        new_state_eta = prev_state_eta + self.delta_t*dot_eta\n",
        "        new_state_s = prev_state_s + self.delta_t*dot_s\n",
        "\n",
        "        next_state = tf.concat([new_state_v,  new_state_eta, new_state_s], axis=1)\n",
        "        return [new_state_v-self.state_v_ref, new_state_eta, action_network, action_node_p, action_node_i], [next_state]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WhVxTo3W78Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loop_seed = 5\n",
        "PI_NNMatrix_list = []\n",
        "loss_list = []\n",
        "loss_all_list = []\n",
        "\n",
        "Comp_time_list = []\n",
        "\n",
        "\n",
        "episodes =400 # total number of iterations to update weights\n",
        "# action_units = dim_edge\n",
        "# action_units_edge, action_units_node_p, action_units_node_i\n",
        "\n",
        "units = dim_action*2 + dim_edge #dimension of each state\n",
        "internal_units=20 # demension of the neural network for control policy\n",
        "internal_units_NNMatrix = 20\n",
        "\n",
        "T = 300  #Total period considered\n",
        "Batch_num=300 # number of batch in each episodes\n",
        "PrintUpdate=1\n",
        "ref_v_upper = 6\n",
        "ref_v_lower = 5\n",
        "\n",
        "for loop in range(0,loop_seed):\n",
        "    print('loop', loop)\n",
        "    random.seed(datetime.now())\n",
        "    start = time.time()\n",
        "\n",
        "\n",
        "    cell = MinimalRNNCell_NNMatrix(units, dim_edge ,dim_action, dim_action, internal_units, internal_units_NNMatrix,env,Batch_num)\n",
        "    layer = RNN(cell,return_sequences=True,stateful = True)\n",
        "    input_1 = tf.keras.Input(batch_shape=(Batch_num,T,units))\n",
        "    outputs = layer((input_1))\n",
        "    model_NNMatrix = tf.keras.models.Model([input_1], outputs)\n",
        "    model_NNMatrix.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "\n",
        "    x0=np.ones((Batch_num,T,units))\n",
        "    y0=model_NNMatrix(x0)\n",
        "    Loss_record_NNMatrix=[]\n",
        "    Loss_all_record_NNMatrix=[]\n",
        "    global_step = tf.Variable(0, trainable=False)\n",
        "    learning_rate_initial=0.035\n",
        "    decayed_lr =tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        learning_rate_initial, 50, 0.7, staircase=True)\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=decayed_lr)\n",
        "\n",
        "\n",
        "    for i in range(0,episodes):\n",
        "        start_in = time.time()\n",
        "        cell.state_v_ref = tf.constant(np.random.uniform(ref_v_lower,ref_v_upper,(Batch_num, 1))@\n",
        "                                       np.ones((1,dim_action)),dtype=tf.float32)\n",
        "        initial_state1 = v0_nom*np.ones((Batch_num,dim_action)) + v0_random*np.random.uniform(0,1.,(Batch_num, dim_action))\n",
        "        initial_state2 = env.eta0*np.ones((Batch_num,dim_edge))\n",
        "        initial_state3 = np.zeros((Batch_num, dim_action))\n",
        "        initial_state = np.hstack((initial_state1, initial_state2, initial_state3))\n",
        "        layer.reset_states( initial_state)\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            [new_state_v, new_state_eta, action_edge, action_P, action_I]=model_NNMatrix(x0)\n",
        "\n",
        "    ##################\n",
        "            loss_state1 =1* K.sum(K.relu(-new_state_eta+1))/Batch_num/units\n",
        "\n",
        "            state_v_minus_ref = new_state_v\n",
        "            loss_state3 = K.sum(K.abs(state_v_minus_ref))/Batch_num/units\n",
        "            loss_action_edge = 0.01*K.sum(K.pow(action_edge, 2))/Batch_num/units\n",
        "            loss_action_w = 0.05*K.sum(K.pow(action_P+action_I,2)@env.diag_c)/Batch_num/units\n",
        "            loss = (loss_state3 + loss_action_edge + loss_action_w)\n",
        "            loss_state_large = 10*K.sum(K.relu(K.abs(state_v_minus_ref)-5))/Batch_num/units\n",
        "            loss_all = loss + loss_state_large\n",
        "\n",
        "        grads = tape.gradient(loss, model_NNMatrix.variables)\n",
        "        optimizer.apply_gradients(zip(grads, model_NNMatrix.variables))\n",
        "        Loss_record_NNMatrix.append(loss)\n",
        "        Loss_all_record_NNMatrix.append(loss_all)\n",
        "        if i % (PrintUpdate) == 0:\n",
        "            print('episode',i, 'loss_all',loss_all, 'Loss',loss, 'loss_state_large', loss_state_large)\n",
        "            print('   Loss_v_minus_ref',loss_state3, 'Loss_eta',loss_state1  )\n",
        "            print('   Loss_u_edge', loss_action_edge, 'loss_action_w', loss_action_w )\n",
        "            print('   up/ui',K.sum(K.pow(action_P,2)@env.diag_c)/K.sum(K.pow(action_I,2)@env.diag_c))\n",
        "            print('            time,',  time.time()- start_in  )\n",
        "\n",
        "\n",
        "\n",
        "    end = time.time()\n",
        "    print(end - start)\n",
        "    Comp_time_list.append(end - start)\n",
        "    PI_NNMatrix_list.append(model_NNMatrix)\n",
        "    loss_list.append(np.array(Loss_record_NNMatrix))\n",
        "    loss_all_list.append(np.array(Loss_all_record_NNMatrix))\n",
        "\n",
        "\n",
        "\n",
        "print('computation time ', np.array(Comp_time_list))\n",
        "print('computation time mean', np.mean(np.array(Comp_time_list)))\n"
      ],
      "metadata": {
        "id": "ns46lxng78Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(Loss_record_NNMatrix)\n",
        "plt.xlabel('episoid')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Non-Discounted Loss without penalty')"
      ],
      "metadata": {
        "id": "9DBpijgu78My"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "okJiY-38RSXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simulate"
      ],
      "metadata": {
        "id": "IOTnNnZtHG4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural-PI"
      ],
      "metadata": {
        "id": "60P8nworSBLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @tf.function\n",
        "def Action_edge(state, model, env):\n",
        "\n",
        "    w_plus=K.dot(tf.math.square(model.variables[0]),model.w_recover)\n",
        "    b_plus=K.dot(-tf.math.square(model.variables[1]),model.b_recover)\n",
        "    w_minus=K.dot(-tf.math.square(model.variables[2]),model.w_recover)\n",
        "    b_minus=K.dot(-tf.math.square(model.variables[3]),model.b_recover)\n",
        "    nonlinear_plus=K.sum(K.relu(K.dot(tf.linalg.diag(state-env.eta0),model.ones_edge)+b_plus)\\\n",
        "                    *w_plus,axis=2)\n",
        "    nonlinear_minus=K.sum(K.relu(-K.dot(tf.linalg.diag(state-env.eta0),model.ones_edge)+b_minus)\\\n",
        "                    *w_minus,axis=2)\n",
        "    action_nonconstrain0= nonlinear_plus+nonlinear_minus\n",
        "    action=env.max_action_edge-np_relu(env.max_action_edge-action_nonconstrain0)\\\n",
        "            +np_relu(-env.max_action_edge-action_nonconstrain0)\n",
        "\n",
        "    return action\n",
        "\n",
        "@tf.function\n",
        "def Action_ICNN_P(obs, model, env):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(obs)\n",
        "        z1 = model.softplus_beta(K.dot(obs, model.variables[4])+ model.variables[5])\n",
        "        z2 = model.softplus_beta(K.dot(obs, model.variables[6])+K.dot(z1, model.variables[7])+ model.variables[8])\n",
        "        z3 = model.softplus_beta(K.dot(obs, model.variables[9])+K.dot(z2, model.variables[10])+ model.variables[11])\n",
        "\n",
        "    return tf.squeeze(tape.batch_jacobian(z3, obs))\n",
        "\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def Action_ICNN_I(obs, model, env):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(obs)\n",
        "        z1 = model.softplus_beta(K.dot(obs, model.variables[12])+ model.variables[13])\n",
        "        z2 = model.softplus_beta(K.dot(obs, model.variables[14])+K.dot(z1, model.variables[15])+ model.variables[16])\n",
        "        z3 = model.softplus_beta(K.dot(obs, model.variables[17])+K.dot(z2, model.variables[18])+ model.variables[19])\n",
        "\n",
        "    return tf.squeeze(tape.batch_jacobian(z3, obs), axis=0)\n",
        "\n",
        "\n",
        "#\n",
        "###########    add\n",
        "def Action_ICNN(state_x, state_s, model, env):\n",
        "\n",
        "    action_nonconstrain0 = Action_ICNN_P(-state_x+env.state_v_ref, model, env)\\\n",
        "                          -Action_ICNN_P(model.obs_zeros, model, env)\n",
        "    action_nonconstrain1 = Action_ICNN_I(state_s,model, env)-Action_ICNN_I(model.obs_zeros, model, env)\n",
        "    action_nonconstrain =  action_nonconstrain0 + action_nonconstrain1\n",
        "    return action_nonconstrain, action_nonconstrain0, action_nonconstrain1\n"
      ],
      "metadata": {
        "id": "t1QEQqXhsZy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7_9LYIF7sZy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the trajectory to visulize the performance of control\n",
        "Trajectory_Linear = []\n",
        "Trajectory_eta_Linear = []\n",
        "Trajectory_s_Linear = []\n",
        "\n",
        "init_state = np.array([[4.5481234, 4.4400673, 3.0106626, 4.648548 , 3.862493 , 3.4021516,\n",
        "        4.1023088, 6.730633 , 4.2614346, 5.3563185, 5.5848107, 5.681905 ,\n",
        "        3.5720792, 4.010938 , 6.539898 , 3.4076588, 6.5165396, 4.065842 ,\n",
        "        6.97986  , 5.6366544 ]], dtype=np.float32)\n",
        "# (v0_nom*np.ones(dim_action,dtype=np.float32) +\n",
        "              # v0_random*np.random.uniform(0,1.,(dim_action)).astype(np.float32)).reshape((1, -1))\n",
        "\n",
        "# v0.reshape((1, -1))\n",
        "linear_coff_s = np.ones((1,dim_action),dtype=np.float32)*(2)\n",
        "linear_coff_x = linear_coff= np.ones((1,dim_action),dtype=np.float32)*10\n",
        "\n",
        "x = init_state\n",
        "action_s = np.zeros((1,dim_action),dtype=np.float32)\n",
        "\n",
        "env.set_state(x)\n",
        "\n",
        "Trajectory_Linear.append(x)\n",
        "Trajectory_eta_Linear.append(env.state_eta)\n",
        "\n",
        "SimulationLength=760\n",
        "Record_u_Linear=[]\n",
        "Record_Loss_Linear=[]\n",
        "Record_action_network_Linear=[]\n",
        "Loss_Linear=0\n",
        "state_s = np.zeros((1,dim_action),dtype=np.float32)\n",
        "Record_up=[]\n",
        "Record_ui=[]\n",
        "record_grad_ui = []\n",
        "Trajectory_s_Linear.append(env.state_s)\n",
        "\n",
        "for i in range(SimulationLength):\n",
        "\n",
        "\n",
        "    action_edgefeedback = Action_edge(env.state_eta, PI_SCNN_list[0], env)\n",
        "\n",
        "    u, up, ui = Action_ICNN(x, state_s, PI_SCNN_list[0], env)\n",
        "    next_state_s, next_state_v, next_state_eta, r, action_network= env.step_edge_WoCost(action_edgefeedback, up, ui)\n",
        "\n",
        "    Loss_Linear+=r\n",
        "    x = next_state_v\n",
        "    state_s = next_state_s\n",
        "    Trajectory_Linear.append(x)\n",
        "    Trajectory_eta_Linear.append(next_state_eta)\n",
        "    Trajectory_s_Linear.append(next_state_s)\n",
        "    Record_u_Linear.append(np.squeeze(u))\n",
        "    Record_up.append(np.squeeze(up))\n",
        "    Record_ui.append(np.squeeze(ui))\n",
        "    Record_action_network_Linear.append(np.squeeze(action_network))\n",
        "    Record_Loss_Linear.append(np.squeeze(r))\n",
        "    record_grad_ui.append(np.squeeze(env.calc_grad_action(ui)[1]))\n",
        "\n",
        "Trajectory_Linear = np.squeeze(np.asarray(Trajectory_Linear))\n",
        "Trajectory_s_Linear = np.squeeze(np.asarray(Trajectory_s_Linear))\n",
        "record_grad_ui = np.squeeze(np.asarray(record_grad_ui))\n",
        "Record_u_Linear = np.squeeze(np.asarray(Record_u_Linear))\n",
        "fig = plt.figure(figsize=(11,10), dpi=100)\n",
        "\n",
        "plt.subplot(4,2,1)\n",
        "\n",
        "\n",
        "TimeRecord=np.arange(1,SimulationLength+1)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Record_u_Linear)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('Action_total')\n",
        "\n",
        "plt.subplot(4,2,2)\n",
        "TimeRecord=np.arange(1,SimulationLength+1)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Record_action_network_Linear)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('Action_network')\n",
        "\n",
        "plt.subplot(4,2,3)\n",
        "\n",
        "TimeRecord=np.arange(1,SimulationLength+2)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Trajectory_Linear)\n",
        "\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('speed')\n",
        "\n",
        "Trajectory_eta_Linear=np.squeeze(np.asarray(Trajectory_eta_Linear))\n",
        "\n",
        "plt.subplot(4,2,4)\n",
        "plt.plot(TimeRecord,Trajectory_eta_Linear)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('position')\n",
        "\n",
        "plt.subplot(4,2,5)\n",
        "TimeRecord=np.arange(1,SimulationLength+1)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Record_up)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('Action u_p')\n",
        "\n",
        "\n",
        "plt.subplot(4,2,6)\n",
        "TimeRecord=np.arange(1,SimulationLength+1)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Record_ui)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('Action u_i')\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.subplot(4,2,7)\n",
        "TimeRecord=np.arange(1,SimulationLength+2)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Trajectory_s_Linear)\n",
        "\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('state_s')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(4,2,8)\n",
        "TimeRecord=np.arange(1,SimulationLength+1)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,record_grad_ui)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('grad u_i')\n",
        "fig.tight_layout()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R-B6h1RhJ9N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear-PI"
      ],
      "metadata": {
        "id": "yLGgwDHfSEOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @tf.function\n",
        "def Action_Linear_edge(state, model, env):\n",
        "    action_nonconstrain0 = (state-env.eta0)*abs(model.variables[0])\n",
        "    action=env.max_action_edge-np_relu(env.max_action_edge-action_nonconstrain0)\\\n",
        "            +np_relu(-env.max_action_edge-action_nonconstrain0)\n",
        "    return action\n",
        "\n",
        "@tf.function\n",
        "def Action_Linear_P(obs, model, env):\n",
        "    z1 = K.dot(obs,  model.variables[1])\n",
        "    return z1\n",
        "\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def Action_Linear_I(obs, model, env):\n",
        "    z1 = K.dot(obs,  model.variables[2])\n",
        "    return z1\n",
        "\n",
        "###########    add\n",
        "def Action_Linear(state_x, state_s, model, env):\n",
        "\n",
        "    action_nonconstrain0 = Action_Linear_P(-state_x+env.state_v_ref, model, env)\n",
        "    action_nonconstrain1 = Action_Linear_I(state_s,model, env)\n",
        "    action_nonconstrain =  action_nonconstrain0 + action_nonconstrain1\n",
        "\n",
        "    return action_nonconstrain, action_nonconstrain0, action_nonconstrain1\n"
      ],
      "metadata": {
        "id": "jPw22L6vSGSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the trajectory to visulize the performance of control\n",
        "\n",
        "Trajectory_Linear = []\n",
        "Trajectory_eta_Linear = []\n",
        "Trajectory_s_Linear = []\n",
        "\n",
        "init_state = np.array([[4.5481234, 4.4400673, 3.0106626, 4.648548 , 3.862493 , 3.4021516,\n",
        "        4.1023088, 6.730633 , 4.2614346, 5.3563185, 5.5848107, 5.681905 ,\n",
        "        3.5720792, 4.010938 , 6.539898 , 3.4076588, 6.5165396, 4.065842 ,\n",
        "        6.97986  , 5.6366544 ]], dtype=np.float32)\n",
        "# (v0_nom*np.ones(dim_action,dtype=np.float32) +\n",
        "              # v0_random*np.random.uniform(0,1.,(dim_action)).astype(np.float32)).reshape((1, -1))\n",
        "\n",
        "# v0.reshape((1, -1))\n",
        "linear_coff_s = np.ones((1,dim_action),dtype=np.float32)*(2)\n",
        "linear_coff_x = linear_coff= np.ones((1,dim_action),dtype=np.float32)*10\n",
        "\n",
        "x = init_state\n",
        "action_s = np.zeros((1,dim_action),dtype=np.float32)\n",
        "\n",
        "env.set_state(x)\n",
        "\n",
        "Trajectory_Linear.append(x)\n",
        "Trajectory_eta_Linear.append(env.state_eta)\n",
        "\n",
        "SimulationLength=760\n",
        "Record_u_Linear=[]\n",
        "Record_Loss_Linear=[]\n",
        "Record_action_network_Linear=[]\n",
        "Loss_Linear=0\n",
        "state_s = np.zeros((1,dim_action),dtype=np.float32)\n",
        "Record_up=[]\n",
        "Record_ui=[]\n",
        "record_grad_ui = []\n",
        "Trajectory_s_Linear.append(env.state_s)\n",
        "\n",
        "for i in range(SimulationLength):\n",
        "\n",
        "    id_model =3\n",
        "\n",
        "    action_edgefeedback = Action_Linear_edge(env.state_eta,  PI_Linear_list[id_model], env)\n",
        "\n",
        "    u, up, ui = Action_Linear(x, state_s,  PI_Linear_list[id_model], env)\n",
        "\n",
        "    next_state_s, next_state_v, next_state_eta, r, action_network= env.step_edge_WoCost(action_edgefeedback, up, ui)\n",
        "\n",
        "    Loss_Linear+=r\n",
        "    x = next_state_v\n",
        "    state_s = next_state_s\n",
        "    Trajectory_Linear.append(x)\n",
        "    Trajectory_eta_Linear.append(next_state_eta)\n",
        "    Trajectory_s_Linear.append(next_state_s)\n",
        "    Record_u_Linear.append(np.squeeze(u))\n",
        "    Record_up.append(np.squeeze(up))\n",
        "    Record_ui.append(np.squeeze(ui))\n",
        "    Record_action_network_Linear.append(np.squeeze(action_network))\n",
        "    Record_Loss_Linear.append(np.squeeze(r))\n",
        "    record_grad_ui.append(np.squeeze(env.calc_grad_action(ui)[1]))\n",
        "\n",
        "Trajectory_Linear = np.squeeze(np.asarray(Trajectory_Linear))\n",
        "Trajectory_s_Linear = np.squeeze(np.asarray(Trajectory_s_Linear))\n",
        "record_grad_ui = np.squeeze(np.asarray(record_grad_ui))\n",
        "Record_u_Linear = np.squeeze(np.asarray(Record_u_Linear))\n",
        "fig = plt.figure(figsize=(11,10), dpi=100)\n",
        "\n",
        "plt.subplot(4,2,1)\n",
        "\n",
        "\n",
        "TimeRecord=np.arange(1,SimulationLength+1)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Record_u_Linear)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('Action_total')\n",
        "\n",
        "plt.subplot(4,2,2)\n",
        "TimeRecord=np.arange(1,SimulationLength+1)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Record_action_network_Linear)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('Action_network')\n",
        "\n",
        "plt.subplot(4,2,3)\n",
        "\n",
        "TimeRecord=np.arange(1,SimulationLength+2)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Trajectory_Linear)\n",
        "\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('speed')\n",
        "\n",
        "Trajectory_eta_Linear=np.squeeze(np.asarray(Trajectory_eta_Linear))\n",
        "\n",
        "plt.subplot(4,2,4)\n",
        "plt.plot(TimeRecord,Trajectory_eta_Linear)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('position')\n",
        "\n",
        "plt.subplot(4,2,5)\n",
        "TimeRecord=np.arange(1,SimulationLength+1)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Record_up)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('Action u_p')\n",
        "\n",
        "\n",
        "plt.subplot(4,2,6)\n",
        "TimeRecord=np.arange(1,SimulationLength+1)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Record_ui)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('Action u_i')\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.subplot(4,2,7)\n",
        "TimeRecord=np.arange(1,SimulationLength+2)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Trajectory_s_Linear)\n",
        "\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('state_s')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(4,2,8)\n",
        "TimeRecord=np.arange(1,SimulationLength+1)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,record_grad_ui)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('grad u_i')\n",
        "fig.tight_layout()\n"
      ],
      "metadata": {
        "id": "gsRSAk3DfeA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNN-PI"
      ],
      "metadata": {
        "id": "Fev-P4-kTAM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @tf.function\n",
        "def Action_edge(state, model, env):\n",
        "    action_nonconstrain0= K.sum(K.relu(K.dot(tf.linalg.diag(state-env.eta0),model.variables[0])+model.variables[1])*\\\n",
        "                  model.variables[2]+model.variables[3],axis=2)\n",
        "    action=env.max_action_edge-np_relu(env.max_action_edge-action_nonconstrain0)\\\n",
        "            +np_relu(-env.max_action_edge-action_nonconstrain0)\n",
        "    return action\n",
        "\n",
        "@tf.function\n",
        "def Action_NNMatrix_P(obs, model, env):\n",
        "    z1 = K.softplus(K.dot(obs, model.variables[4])+ model.variables[5])\n",
        "    z2 = K.softplus(K.dot(obs, model.variables[6])+K.dot(z1, model.variables[7])+ model.variables[8])\n",
        "    z3 = K.dot(obs, model.variables[9])+K.dot(z2, model.variables[10])+ model.variables[11]\n",
        "    return z3\n",
        "\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def Action_NNMatrix_I(obs, model, env):\n",
        "\n",
        "    z1 = K.softplus(K.dot(obs, model.variables[12])+ model.variables[13])\n",
        "    z2 = K.softplus(K.dot(obs, model.variables[14])+K.dot(z1, model.variables[15])+ model.variables[16])\n",
        "    z3 = K.dot(obs, model.variables[17])+K.dot(z2, model.variables[18])+ model.variables[19]\n",
        "    return z3\n",
        "\n",
        "#\n",
        "###########    add\n",
        "def Action_NNMatrix(state_x, state_s, model, env):\n",
        "\n",
        "    action_nonconstrain0 = Action_NNMatrix_P(-state_x+env.state_v_ref, model, env)\n",
        "    action_nonconstrain1 = Action_NNMatrix_I(state_s,model, env)\n",
        "    action_nonconstrain =  action_nonconstrain0 + action_nonconstrain1\n",
        "    return action_nonconstrain, action_nonconstrain0, action_nonconstrain1\n"
      ],
      "metadata": {
        "id": "9808H46KTE-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the trajectory to visulize the performance of control\n",
        "\n",
        "Trajectory_Linear = []\n",
        "Trajectory_eta_Linear = []\n",
        "Trajectory_s_Linear = []\n",
        "\n",
        "init_state = np.array([[4.5481234, 4.4400673, 3.0106626, 4.648548 , 3.862493 , 3.4021516,\n",
        "        4.1023088, 6.730633 , 4.2614346, 5.3563185, 5.5848107, 5.681905 ,\n",
        "        3.5720792, 4.010938 , 6.539898 , 3.4076588, 6.5165396, 4.065842 ,\n",
        "        6.97986  , 5.6366544 ]], dtype=np.float32)\n",
        "# (v0_nom*np.ones(dim_action,dtype=np.float32) +\n",
        "              # v0_random*np.random.uniform(0,1.,(dim_action)).astype(np.float32)).reshape((1, -1))\n",
        "\n",
        "# v0.reshape((1, -1))\n",
        "linear_coff_s = np.ones((1,dim_action),dtype=np.float32)*(2)\n",
        "linear_coff_x = linear_coff= np.ones((1,dim_action),dtype=np.float32)*10\n",
        "\n",
        "x = init_state\n",
        "action_s = np.zeros((1,dim_action),dtype=np.float32)\n",
        "\n",
        "env.set_state(x)\n",
        "\n",
        "Trajectory_Linear.append(x)\n",
        "Trajectory_eta_Linear.append(env.state_eta)\n",
        "\n",
        "SimulationLength=760\n",
        "Record_u_Linear=[]\n",
        "Record_Loss_Linear=[]\n",
        "Record_action_network_Linear=[]\n",
        "Loss_Linear=0\n",
        "state_s = np.zeros((1,dim_action),dtype=np.float32)\n",
        "Record_up=[]\n",
        "Record_ui=[]\n",
        "record_grad_ui = []\n",
        "Trajectory_s_Linear.append(env.state_s)\n",
        "\n",
        "for i in range(SimulationLength):\n",
        "\n",
        "\n",
        "    id_model = 0\n",
        "    action_edgefeedback = Action_edge(env.state_eta, PI_NNMatrix_list[id_model], env)\n",
        "    u, up, ui = Action_NNMatrix(x, state_s,PI_NNMatrix_list[id_model], env)\n",
        "    next_state_s, next_state_v, next_state_eta, r, action_network= env.step_edge_WoCost(action_edgefeedback, up, ui)\n",
        "\n",
        "    Loss_Linear+=r\n",
        "    x = next_state_v\n",
        "    state_s = next_state_s\n",
        "    Trajectory_Linear.append(x)\n",
        "    Trajectory_eta_Linear.append(next_state_eta)\n",
        "    Trajectory_s_Linear.append(next_state_s)\n",
        "    Record_u_Linear.append(np.squeeze(u))\n",
        "    Record_up.append(np.squeeze(up))\n",
        "    Record_ui.append(np.squeeze(ui))\n",
        "    Record_action_network_Linear.append(np.squeeze(action_network))\n",
        "    Record_Loss_Linear.append(np.squeeze(r))\n",
        "    record_grad_ui.append(np.squeeze(env.calc_grad_action(ui)[1]))\n",
        "\n",
        "Trajectory_Linear = np.squeeze(np.asarray(Trajectory_Linear))\n",
        "Trajectory_s_Linear = np.squeeze(np.asarray(Trajectory_s_Linear))\n",
        "record_grad_ui = np.squeeze(np.asarray(record_grad_ui))\n",
        "Record_u_Linear = np.squeeze(np.asarray(Record_u_Linear))\n",
        "fig = plt.figure(figsize=(11,10), dpi=100)\n",
        "\n",
        "plt.subplot(4,2,1)\n",
        "\n",
        "\n",
        "TimeRecord=np.arange(1,SimulationLength+1)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Record_u_Linear)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('Action_total')\n",
        "\n",
        "plt.subplot(4,2,2)\n",
        "TimeRecord=np.arange(1,SimulationLength+1)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Record_action_network_Linear)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('Action_network')\n",
        "\n",
        "plt.subplot(4,2,3)\n",
        "\n",
        "TimeRecord=np.arange(1,SimulationLength+2)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Trajectory_Linear)\n",
        "\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('speed')\n",
        "\n",
        "Trajectory_eta_Linear=np.squeeze(np.asarray(Trajectory_eta_Linear))\n",
        "\n",
        "plt.subplot(4,2,4)\n",
        "plt.plot(TimeRecord,Trajectory_eta_Linear)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('position')\n",
        "\n",
        "plt.subplot(4,2,5)\n",
        "TimeRecord=np.arange(1,SimulationLength+1)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Record_up)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('Action u_p')\n",
        "\n",
        "\n",
        "plt.subplot(4,2,6)\n",
        "TimeRecord=np.arange(1,SimulationLength+1)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Record_ui)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('Action u_i')\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.subplot(4,2,7)\n",
        "TimeRecord=np.arange(1,SimulationLength+2)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,Trajectory_s_Linear)\n",
        "\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('state_s')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(4,2,8)\n",
        "TimeRecord=np.arange(1,SimulationLength+1)\n",
        "TimeRecord=env.delta_t*TimeRecord\n",
        "plt.plot(TimeRecord,record_grad_ui)\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('grad u_i')\n",
        "fig.tight_layout()\n"
      ],
      "metadata": {
        "id": "Kv1hN9tVbaNH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}